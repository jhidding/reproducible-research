<section>
<section id="motivation" class="title-slide slide level1">
<h1>Motivation</h1>

</section>
<section id="a-typical-sitation" class="slide level2">
<h2>A typical sitation</h2>
<figure>
<img data-src="./img/research_comic_phd.gif" alt="PhD Comic" /><figcaption aria-hidden="true">PhD Comic</figcaption>
</figure>
</section>
<section id="discussion-a-scary-anecdote" class="slide level2">
<h2>Discussion: A scary anecdote</h2>
<ul>
<li class="fragment">A group of researchers obtain great results and submit their work to a high-profile journal.</li>
<li class="fragment">Reviewers ask for new figures and additional analysis.</li>
<li class="fragment">The researchers start working on revisions and generate modified figures, but find inconsistencies with old figures.</li>
<li class="fragment">The researchers can’t find some of the data they used to generate the original results, and can’t figure out which parameters they used when running their analyses.</li>
</ul>
</section>
<section id="discussion-continued" class="slide level2">
<h2>Discussion: continued …</h2>
<ul>
<li class="fragment">The manuscript is still languishing in the drawer …</li>
</ul>
</section></section>
<section>
<section id="what-is-reproducible-research" class="title-slide slide level1">
<h1>What is reproducible research?</h1>

</section>
<section id="definition" class="slide level2">
<h2>Definition</h2>
<div style="font-size: smaller">
<blockquote>
<p>“reproducibility refers to the ability of a researcher to <strong>duplicate the results</strong> of a prior study using the same materials as were used by the original investigator. That is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results. Reproducibility is a <strong>minimum necessary condition</strong> for a finding to be believable and informative.”</p>
<p>– <cite> U.S. National Science Foundation (NSF) subcommittee on replicability in science</cite></p>
</blockquote>
</div>
</section>
<section id="definition-1" class="slide level2">
<h2>Definition</h2>
<ul>
<li>For any research project, an independent researcher should be able to replicate an experiment:
<ul>
<li>the same results should be obtained under the same contitions</li>
<li>it should be possible to recreate the same conditions</li>
</ul></li>
<li>“Experiment” is interpreted in a wide sense, encompassing also computational work</li>
</ul>
</section></section>
<section>
<section id="the-reproducibility-crisis" class="title-slide slide level1">
<h1>The Reproducibility Crisis</h1>

</section>
<section id="why-all-the-talk" class="slide level2">
<h2>Why all the talk?</h2>
<p><img data-src="./img/reproducibility_nature.jpg" /> ::: {.notes} A 2016 <a href="http://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970">survey</a> in Nature revealed that irreproducible experiments are a problem across all domains of science. :::</p>
</section>
<section id="factors-behind-irreproducible-research" class="slide level2">
<h2>Factors behind irreproducible research</h2>
<ul>
<li>Not enough documentation on how experiment is conducted and data is generated</li>
<li>Data used to generate original results unavailable</li>
<li>Software used to generate original results unavailable</li>
<li>Difficult to recreate software environment (libraries, versions) used to generate original results</li>
<li>Difficult to rerun the computational steps</li>
</ul>
</section>
<section id="or-in-short" class="slide level2">
<h2>Or in short</h2>
<p><img data-src="./img/Miracle.jpg" /></p>
</section>
<section id="levels-of-reproducibility" class="slide level2">
<h2>Levels of reproducibility</h2>
<aside class="notes">
<p>A published article is like the top of a pyramid. It rests on multiple levels that each contributes to its reproducibility.</p>
</aside>
<p><img data-src="./img/repro-pyramid.png" /></p>
</section></section>
<section>
<section id="reproducible-replicable-robust-generalisable" class="title-slide slide level1">
<h1>Reproducible, replicable, robust, generalisable</h1>

</section>
<section id="the-four-riders" class="slide level2">
<h2>The four riders</h2>
<figure>
<img data-src="./img/turing-way/39-reproducible-replicable-robust-generalisable.jpg" alt="CC-BY Scriberia" /><figcaption aria-hidden="true">CC-BY Scriberia</figcaption>
</figure>
<aside class="notes">
<p>(This image was created by <a href="http://www.scriberia.co.uk">Scriberia</a> for <a href="https://the-turing-way.netlify.com">The Turing Way</a> community and is used under a CC-BY licence. The image was obtained from <a href="https://zenodo.org/record/3332808">https://zenodo.org/record/3332808</a>.)</p>
<p>While reproducibility is the minimum requirement and can be solved with “good enough” computational practices, replicability/robustness/generalisability of scientific findings are an even greater concern involving research misconduct, questionable research practices (p-hacking, HARKing, cherry-picking), sloppy methods, and other conscious and unconscious biases.</p>
</aside>
</section>
<section id="discuss-with-your-neighbors-or-among-all-participants" class="slide level2">
<h2>Discuss with your neighbors or among all participants</h2>
<blockquote>
<p>Computer programs are expected to produce the same output for the same inputs. Is that true for research software?</p>
<p>Can you give some examples? What can we do about it?</p>
</blockquote>
</section></section>
